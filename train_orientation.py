import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
from PIL import Image
import os
from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt
from imutils import paths
import progressbar
import argparse
import imutils
import random
import cv2
import os
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import seaborn as sns
import pandas as pd
from sklearn.metrics import confusion_matrix 
import matplotlib.pyplot as plt
import seaborn as sns
from loguru import logger


# construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-d", "--dataset", required=True, help="path to input directory of images")
ap.add_argument("-o", "--output", required=True, help="path to output directory of rotated iamges")
args = vars(ap.parse_args())

# --- CONFIGURATION ---
DATASET_ROOT = args["dataset"]  # Th∆∞ m·ª•c ch·ª©a c√°c ·∫£nh sau khi gi·∫£i n√©n
OUTPUT_DIR = args["output"]       # Th∆∞ m·ª•c ch·ª©a c√°c ·∫£nh ƒë√£ xoay
NUM_EPOCHS = 30                   # S·ªë epochs ƒë·ªÉ hu·∫•n luy·ªán, 3-5 l√† ƒë·ªß cho b√†i to√°n n√†y
BATCH_SIZE = 32                    # T√πy ch·ªânh theo VRAM c·ªßa b·∫°n
LEARNING_RATE = 1e-4               # T·ªëc ƒë·ªô h·ªçc cho l·ªõp classifier
TRAIN_VAL_SPLIT = 0.9              # T·ª∑ l·ªá 90% cho t·∫≠p hu·∫•n luy·ªán, 10% cho t·∫≠p x√°c th·ª±c

# --- 1. DATASET CLASS ---
# T·∫°o m·ªôt Dataset t√πy ch·ªânh ƒë·ªÉ xoay ·∫£nh v√† g√°n nh√£n gi·∫£
class RotationDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.image_paths = []
        # L·∫•y t·∫•t c·∫£ ƒë∆∞·ªùng d·∫´n ·∫£nh t·ª´ c√°c th∆∞ m·ª•c con
        for category in os.listdir(root_dir):
            category_path = os.path.join(root_dir, category)
            if os.path.isdir(category_path):
                for img_name in os.listdir(category_path):
                    if img_name.lower().endswith('.jpg'):
                        self.image_paths.append(os.path.join(category_path, img_name))

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        # M·ªü ·∫£nh g·ªëc
        image = Image.open(img_path).convert('RGB')

        # Ch·ªçn ng·∫´u nhi√™n m·ªôt g√≥c xoay: 0, 90, 180, 270 ƒë·ªô
        # T∆∞∆°ng ·ª©ng v·ªõi c√°c nh√£n 0, 1, 2, 3
        rotation_label = np.random.randint(4)
        rotated_image = image.rotate(rotation_label * 90)

        # √Åp d·ª•ng c√°c ph√©p bi·∫øn ƒë·ªïi (resize, normalize)
        if self.transform:
            tensor_image = self.transform(rotated_image)

        return tensor_image, torch.tensor(rotation_label, dtype=torch.long)

# --- 2. MODEL DEFINITION ---
# ƒê·ªãnh nghƒ©a m√¥ h√¨nh bao g·ªìm DINOv2 v√† m·ªôt l·ªõp classifier
class OrientationClassifier(nn.Module):
    def __init__(self, num_classes=4):
        super(OrientationClassifier, self).__init__()
        # T·∫£i m√¥ h√¨nh DINOv2 ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán s·∫µn t·ª´ PyTorch Hub
        # dinov2_vitb14 l√† phi√™n b·∫£n "base" v·ªõi Vision Transformer
        # self.dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')
        self.dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14_reg')
        
        
        # --- QUAN TR·ªåNG: ƒê√≥ng bƒÉng DINOv2 ---
        # Ch√∫ng ta kh√¥ng mu·ªën hu·∫•n luy·ªán l·∫°i DINOv2, ch·ªâ d√πng n√≥ ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
        for param in self.dinov2.parameters():
            param.requires_grad = False
            
        # L·∫•y s·ªë chi·ªÅu ƒë·∫∑c tr∆∞ng ƒë·∫ßu ra c·ªßa DINOv2 (v·ªõi ViT-Base l√† 768)
        feature_dim = self.dinov2.embed_dim

        # T·∫°o m·ªôt l·ªõp classifier ƒë∆°n gi·∫£n ƒë·ªÉ ph√¢n lo·∫°i 4 g√≥c xoay
        self.classifier = nn.Linear(feature_dim, num_classes)

    def forward(self, x):
        # ƒê∆∞a ·∫£nh qua DINOv2 ƒë·ªÉ l·∫•y vector ƒë·∫∑c tr∆∞ng
        # DINOv2 tr·∫£ v·ªÅ m·ªôt dict, ch√∫ng ta ch·ªâ c·∫ßn feature cu·ªëi c√πng
        features = self.dinov2(x)
        # ƒê∆∞a vector ƒë·∫∑c tr∆∞ng qua l·ªõp classifier
        output = self.classifier(features)
        return output

# --- 3. TRAINING AND VALIDATION LOOP ---
def train_model(train_loader, val_loader, device):
    """
    H√†m hu·∫•n luy·ªán model, tr·∫£ v·ªÅ model ƒë√£ hu·∫•n luy·ªán.
    """
    # Kh·ªüi t·∫°o m√¥ h√¨nh v√† chuy·ªÉn sang device
    model = OrientationClassifier(num_classes=4).to(device)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.classifier.parameters(), lr=LEARNING_RATE)

    # V√≤ng l·∫∑p hu·∫•n luy·ªán
    for epoch in range(NUM_EPOCHS):
        # --- Training phase ---
        model.train()
        running_loss = 0.0
        correct_preds = 0
        total_preds = 0
        
        for inputs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Training]"):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * inputs.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)
        logger.info(f"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {epoch_loss:.4f}")

        # --- Validation phase ---
        model.eval()
        val_loss = 0.0
        correct_preds = 0
        total_preds = 0
        with torch.no_grad():
            for inputs, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Validation]"):
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs.data, 1)
                total_preds += labels.size(0)
                correct_preds += (predicted == labels).sum().item()

        val_epoch_loss = val_loss / len(val_loader.dataset)
        val_epoch_acc = (correct_preds / total_preds) * 100
        logger.info(f"Val Loss: {val_epoch_loss:.4f} | Val Acc: {val_epoch_acc:.2f}%")
        logger.info("-" * 30)

    logger.info("Ho√†n th√†nh hu·∫•n luy·ªán!")
    # L∆∞u l·∫°i ch·ªâ c√°c tr·ªçng s·ªë c·ªßa l·ªõp classifier ƒë√£ hu·∫•n luy·ªán
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
     # L∆∞u m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
    logger.info("\n--- L∆∞u m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ---")
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'orientation_classifier_head.pth'))

    logger.info(f"M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {os.path.join(OUTPUT_DIR, 'orientation_classifier_head.pth')}")
    
    return model


# --- 4. INFERENCE FUNCTION ---
# H√†m ƒë·ªÉ ki·ªÉm tra v√† ch·ªânh s·ª≠a h∆∞·ªõng c·ªßa m·ªôt ·∫£nh m·ªõi
def correct_image_orientation(image_path, model, transform):
    device = next(model.parameters()).device
    model.eval()

    # M·ªü ·∫£nh v√† xoay n√≥ m·ªôt g√≥c ng·∫´u nhi√™n ƒë·ªÉ th·ª≠ nghi·ªám
    original_image = Image.open(image_path).convert('RGB')
    random_rotation_deg = np.random.choice([90, 180, 270])
    test_image = original_image.rotate(random_rotation_deg, expand=True)
    logger.info(f"·∫¢nh ƒë√£ ƒë∆∞·ª£c xoay ƒëi {random_rotation_deg} ƒë·ªô ƒë·ªÉ ki·ªÉm tra.")

    # Chu·∫©n b·ªã ·∫£nh ƒë·∫ßu v√†o cho model
    input_tensor = transform(test_image).unsqueeze(0).to(device)

    # D·ª± ƒëo√°n
    with torch.no_grad():
        output = model(input_tensor)
        _, predicted_label = torch.max(output.data, 1)
        predicted_rotation = predicted_label.item() * 90

    logger.info(f"Model d·ª± ƒëo√°n ·∫£nh ƒë√£ b·ªã xoay: {predicted_rotation} ƒë·ªô.")

    # T√≠nh to√°n g√≥c c·∫ßn xoay l·∫°i ƒë·ªÉ ch·ªânh s·ª≠a
    correction_angle = -predicted_rotation
    corrected_image = test_image.rotate(correction_angle, expand=True)
    logger.info(f"√Åp d·ª•ng g√≥c xoay {correction_angle} ƒë·ªô ƒë·ªÉ s·ª≠a l·∫°i.")

    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    axes[0].imshow(original_image)
    axes[0].set_title("·∫¢nh G·ªëc (0¬∞)")
    axes[0].axis('off')

    axes[1].imshow(test_image)
    axes[1].set_title(f"·∫¢nh B·ªã Xoay ({random_rotation_deg}¬∞)")
    axes[1].axis('off')

    axes[2].imshow(corrected_image)
    axes[2].set_title("·∫¢nh ƒê√£ Ch·ªânh S·ª≠a")
    axes[2].axis('off')

    plt.show()



# --- NEW EVALUATION FUNCTION ---
def evaluate_model(model, test_loader, device):
    """
    H√†m ƒë·ªÉ ƒë√°nh gi√° model tr√™n t·∫≠p test.
    """
    logger.info("\n--- B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p Test ---")
    model.eval()  # Chuy·ªÉn model sang ch·∫ø ƒë·ªô ƒë√°nh gi√°
    
    all_labels = []
    all_predictions = []

    # Kh√¥ng t√≠nh to√°n gradient trong qu√° tr√¨nh ƒë√°nh gi√°
    with torch.no_grad():
        for inputs, labels in tqdm(test_loader, desc="Evaluating"):
            inputs, labels = inputs.to(device), labels.to(device)
            
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            
            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # T√≠nh to√°n c√°c ch·ªâ s·ªë
    accuracy = accuracy_score(all_labels, all_predictions)
    report = classification_report(all_labels, all_predictions, target_names=['0¬∞', '90¬∞', '180¬∞', '270¬∞'])
    conf_matrix = confusion_matrix(all_labels, all_predictions)
 
    logger.info(f"\n‚úÖ ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p Test: {accuracy * 100:.2f}%")
    logger.info("\nüìä B√°o c√°o ph√¢n lo·∫°i chi ti·∫øt:")
    logger.info(report)
    logger.info("\nüìà Ma tr·∫≠n nh·∫ßm l·∫´n:")
    logger.info(conf_matrix)

    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['0¬∞', '90¬∞', '180¬∞', '270¬∞'], 
                yticklabels=['0¬∞', '90¬∞', '180¬∞', '270¬∞'])
    plt.xlabel('Nh√£n d·ª± ƒëo√°n (Predicted Label)')
    plt.ylabel('Nh√£n th·∫≠t (True Label)')
    plt.title('Confusion Matrix')
    plt.show()
    
# --- MAIN EXECUTION (UPDATED) ---
if __name__ == '__main__':
    # X√°c ƒë·ªãnh thi·∫øt b·ªã
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"S·ª≠ d·ª•ng thi·∫øt b·ªã: {device}")

    # ƒê·ªãnh nghƒ©a c√°c ph√©p bi·∫øn ƒë·ªïi ·∫£nh
    transform = transforms.Compose([
        transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    # Kh·ªüi t·∫°o dataset
    full_dataset = RotationDataset(root_dir=DATASET_ROOT, transform=transform)
    
    # --- C·∫¨P NH·∫¨T: Chia d·ªØ li·ªáu th√†nh 3 ph·∫ßn: 80% Train, 10% Val, 10% Test ---
    train_size = int(0.8 * len(full_dataset))
    val_size = int(0.1 * len(full_dataset))
    test_size = len(full_dataset) - train_size - val_size
    train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])
    
    logger.info(f"K√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán: {len(train_dataset)}")
    logger.info(f"K√≠ch th∆∞·ªõc t·∫≠p x√°c th·ª±c:  {len(val_dataset)}")
    logger.info(f"K√≠ch th∆∞·ªõc t·∫≠p ki·ªÉm tra:   {len(test_dataset)}")

    # T·∫°o DataLoaders
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)
    
    # Save the dataloader
    if not os.path.exists(f'{OUTPUT_DIR}/data_split'):
        os.makedirs(f'{OUTPUT_DIR}/data_split')
    torch.save(train_loader, f'{OUTPUT_DIR}/data_split/train_loader.pt')
    torch.save(val_loader, f'{OUTPUT_DIR}/data_split/val_loader.pt')
    torch.save(test_loader, f'{OUTPUT_DIR}/data_split/test_loader.pt')

    # 1. Hu·∫•n luy·ªán m√¥ h√¨nh
    trained_model = train_model(train_loader, val_loader, device)
    
    # 2. ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p Test
    evaluate_model(trained_model, test_loader, device)

    # 3. Th·ª≠ nghi·ªám ch·ªânh s·ª≠a m·ªôt ·∫£nh
    logger.info("\n--- Th·ª≠ nghi·ªám ch·ªânh s·ª≠a m·ªôt ·∫£nh ng·∫´u nhi√™n ---")
    # test_image_path = os.path.join(DATASET_ROOT, 'office', 'image_0010.jpg') 
    # test_image_path = random.choice(test_dataset.image_paths)  # Ch·ªçn ng·∫´u nhi√™n m·ªôt ·∫£nh t·ª´ t·∫≠p test
    test_image_path = '/content/image_orientation/indoor_cvpr/Images/airport_inside/airport_inside_0001.jpg'
    correct_image_orientation(test_image_path, trained_model, transform)